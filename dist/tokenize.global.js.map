{"version":3,"sources":["../src/cst.ts","../src/tokenize.ts"],"sourcesContent":["enum TokenType {\n  Number,\n  Operator,\n\n  LeftParen,\n  RightParen,\n  LeftBracket,\n  RightBracket,\n  LeftBrace,\n  RightBrace,\n\n  String,\n  HexNumStr,\n  BinNumStr,\n  OctNumStr,\n\n  Vector,\n  List,\n\n  Unknown,\n  EOF\n}\n\nenum StackType {\n  Number,\n  String,\n  Vector,\n  List,\n  Unknown\n}\n\nclass Token {\n  constructor(\n    public type: TokenType,\n    public value: string\n  ) { }\n}\n\nexport { TokenType, StackType, Token }","import { Token, TokenType } from './cst';\n\nfunction tokenize(expression: string): Token[] {\n  const tokens: Token[] = [];\n  const length = expression.length;\n  let i = 0;\n\n  const get = (_i = i) => expression[_i];\n  const look = (_i = 1) => get(expression.length - 1 - _i);\n  const peek = (_i = 1) => get(expression.length);\n  const peekI = (_i = 1) => get(i + _i);\n\n  const pushToken = (type: TokenType, value: string) => tokens.push(new Token(type, value));\n  const pushChar = (type: TokenType) => pushToken(type, expression[i]);\n\n  while (i < length) {\n    const char = expression[i];\n\n    if (/\\d/.test(char)) {\n      // Handle numbers\n      let numStr = char;\n      while (i + 1 < length && (/\\d/.test(peekI()) || (peekI() === '.' && !numStr.includes('.')))) {\n        numStr += get(++i);\n      }\n      pushToken(TokenType.Number, numStr);\n    }\n    else if (/[+\\-*/^]/.test(char)) {\n      // Handle operators\n      pushChar(TokenType.Operator);\n    }\n    else if (char === '(') {\n      // Handle left parenthesis\n      pushChar(TokenType.LeftParen);\n    }\n    else if (char === ')') {\n      // Handle right parenthesis\n      pushChar(TokenType.RightParen);\n    }\n    else if (/\\s/.test(char)) {\n      // Ignore whitespace\n    }\n    else if (/0x[0-9A-Fa-f]+/.test(char + peek(1))) {\n      // Handle hexadecimal numbers\n      let hexStr = '';\n      while (i < length && /[0-9A-Fa-f]/.test(expression[i + (hexStr.length > 0 ? 0 : 1)])) {\n        hexStr += get(i++);\n      }\n      // pushToken(TokenType.Number, parseInt(hexStr, 16).toString())\n      pushToken(TokenType.HexNumStr, hexStr);\n    }\n    else if (/0b[01]+/.test(char + peek(1))) {\n      // Handle binary numbers\n      let binStr = '';\n      while (i < length && /[01]/.test(expression[i + (binStr.length > 0 ? 0 : 1)])) {\n        binStr += get(i++);\n      }\n      // pushToken(TokenType.Number, parseInt(binStr, 2).toString())\n      pushToken(TokenType.BinNumStr, binStr);\n    }\n    else if (/0o[0-7]+/.test(char + peek(1))) {\n      // Handle octal numbers\n      let octStr = '';\n      while (i < length && /[0-7]/.test(expression[i + (octStr.length > 0 ? 0 : 1)])) {\n        octStr += get(i++);\n      }\n      // pushToken(TokenType.Number, parseInt(octStr, 8).toString())\n      pushToken(TokenType.OctNumStr, octStr);\n    }\n    else if (char === '\"' || char === \"'\" || char === \"`\") {\n      let str = '';\n      while (i < length && (\n        char !== expression[i] ||\n        (char === expression[i] && look() !== char) ||\n        (char === expression[i] && look() === char && peek() === char))) {\n        str += get(i++);\n      }\n      pushToken(TokenType.String, str || char + char);\n    }\n    else {\n      throw new Error(`Unknown character: ${char}`);\n    }\n\n    i++;\n  }\n\n  pushToken(TokenType.EOF, '');\n\n  return tokens;\n}\n\nexport { tokenize }"],"mappings":"mBA+BA,IAAMA,EAAN,KAAY,CACV,YACSC,EACAC,EACP,CAFO,UAAAD,EACA,WAAAC,CACL,CACN,EClCA,SAASC,EAASC,EAA6B,CAC7C,IAAMC,EAAkB,CAAC,EACnBC,EAASF,EAAW,OACtBG,EAAI,EAEFC,EAAM,CAACC,EAAKF,IAAMH,EAAWK,CAAE,EAC/BC,EAAO,CAACD,EAAK,IAAMD,EAAIJ,EAAW,OAAS,EAAIK,CAAE,EACjDE,EAAO,CAACF,EAAK,IAAMD,EAAIJ,EAAW,MAAM,EACxCQ,EAAQ,CAACH,EAAK,IAAMD,EAAID,EAAIE,CAAE,EAE9BI,EAAY,CAACC,EAAiBC,IAAkBV,EAAO,KAAK,IAAIW,EAAMF,EAAMC,CAAK,CAAC,EAClFE,EAAYH,GAAoBD,EAAUC,EAAMV,EAAWG,CAAC,CAAC,EAEnE,KAAOA,EAAID,GAAQ,CACjB,IAAMY,EAAOd,EAAWG,CAAC,EAEzB,GAAI,KAAK,KAAKW,CAAI,EAAG,CAEnB,IAAIC,EAASD,EACb,KAAOX,EAAI,EAAID,IAAW,KAAK,KAAKM,EAAM,CAAC,GAAMA,EAAM,IAAM,KAAO,CAACO,EAAO,SAAS,GAAG,IACtFA,GAAUX,EAAI,EAAED,CAAC,EAEnBM,IAA4BM,CAAM,CACpC,SACS,WAAW,KAAKD,CAAI,EAE3BD,GAA2B,UAEpBC,IAAS,IAEhBD,GAA4B,UAErBC,IAAS,IAEhBD,GAA6B,UAEtB,MAAK,KAAKC,CAAI,EAGlB,GAAI,iBAAiB,KAAKA,EAAOP,EAAK,CAAC,CAAC,EAAG,CAE9C,IAAIS,EAAS,GACb,KAAOb,EAAID,GAAU,cAAc,KAAKF,EAAWG,GAAKa,EAAO,OAAS,EAAI,EAAI,EAAE,CAAC,GACjFA,GAAUZ,EAAID,GAAG,EAGnBM,IAA+BO,CAAM,CACvC,SACS,UAAU,KAAKF,EAAOP,EAAK,CAAC,CAAC,EAAG,CAEvC,IAAIU,EAAS,GACb,KAAOd,EAAID,GAAU,OAAO,KAAKF,EAAWG,GAAKc,EAAO,OAAS,EAAI,EAAI,EAAE,CAAC,GAC1EA,GAAUb,EAAID,GAAG,EAGnBM,KAA+BQ,CAAM,CACvC,SACS,WAAW,KAAKH,EAAOP,EAAK,CAAC,CAAC,EAAG,CAExC,IAAIW,EAAS,GACb,KAAOf,EAAID,GAAU,QAAQ,KAAKF,EAAWG,GAAKe,EAAO,OAAS,EAAI,EAAI,EAAE,CAAC,GAC3EA,GAAUd,EAAID,GAAG,EAGnBM,KAA+BS,CAAM,CACvC,SACSJ,IAAS,KAAOA,IAAS,KAAOA,IAAS,IAAK,CACrD,IAAIK,EAAM,GACV,KAAOhB,EAAID,IACTY,IAASd,EAAWG,CAAC,GACpBW,IAASd,EAAWG,CAAC,GAAKG,EAAK,IAAMQ,GACrCA,IAASd,EAAWG,CAAC,GAAKG,EAAK,IAAMQ,GAAQP,EAAK,IAAMO,IACzDK,GAAOf,EAAID,GAAG,EAEhBM,IAA4BU,GAAOL,EAAOA,CAAI,CAChD,KAEE,OAAM,IAAI,MAAM,sBAAsBA,CAAI,EAAE,EAG9CX,GACF,CAEA,OAAAM,KAAyB,EAAE,EAEpBR,CACT","names":["Token","type","value","tokenize","expression","tokens","length","i","get","_i","look","peek","peekI","pushToken","type","value","Token","pushChar","char","numStr","hexStr","binStr","octStr","str"]}